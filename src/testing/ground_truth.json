{
  "test_suite": "RAG System - Spark Project",
  "version": "2.0",
  "created": "2025-11-12",
  "description": "Test suite with actual code fragments in ground_truth_contexts",
  "questions": [
    {
      "id": "Q001",
      "question": "Describe TransportFrameDecoder class",
      "category": "definition",
      "ground_truth_contexts": [
        "*/ public class TransportFrameDecoder extends ChannelInboundHandlerAdapter { public static final String HANDLER_NAME = \"frameDecoder\"; private static final int LENGTH_SIZE = 8; private static final int MAX_FRAME_SIZE = Integer.MAX_VALUE; private static final int UNKNOWN_FRAME_SIZE = -1; private static final long CONSOLIDATE_THRESHOLD = 20 * 1024 * 1024; private final LinkedList<ByteBuf> buffers = new LinkedList<>(); private final ByteBuf frameLenBuf = Unpooled.buffer(LENGTH_SIZE, LENGTH_SIZE); private final long consolidateThreshold; private CompositeByteBuf frameBuf = null; private long consolidatedFrameBufSize = 0; private int consolidatedNumComponents = 0; private long totalSize = 0; private long nextFrameSize = UNKNOWN_FRAME_SIZE; private int frameRemainingBytes = UNKNOWN_FRAME_SIZE; private volatile Interceptor interceptor; public TransportFrameDecoder() { this(CONSOLIDATE_THRESHOLD); } @VisibleForTesting TransportFrameDecoder(long consolidateThreshold) { this.consolidateThreshold = consolidateThreshold; } @Override public void channelRead(ChannelHandlerContext ctx, Object data) throws Exception { ByteBuf in = (ByteBuf) data; buffers.add(in); totalSize += in.readableBytes(); while (!buffers.isEmpty()) { // First, feed the interceptor, and if it's still, active, try again. if (interceptor != null) { ByteBuf first = buffers.getFirst(); int available = first.readableBytes(); if (feedInterceptor(first)) { assert !first.isReadable() : \"Interceptor still active but buffer has data.\"; } int read = available - first.readableBytes(); if (read == available) { buffers.removeFirst().release(); } totalSize -= read; } else { // Interceptor is not active, so try to decode one frame. ByteBuf frame = decodeNext(); if (frame == null) { break; } ctx.fireChannelRead(frame); } } } private long decodeFrameSize() { if (nextFrameSize != UNKNOWN_FRAME_SIZE || totalSize < LENGTH_SIZE) { return nextFrameSize; } // We know there's enough data. If the first buffer contains all the data, great. Otherwise, // hold the bytes for the frame length in a composite buffer until we have enough data to read // the frame size. Normally, it should be rare to need more than one buffer to read the frame // size. ByteBuf first = buffers.getFirst(); if (first.readableBytes() >= LENGTH_SIZE) { nextFrameSize = first.readLong() - LENGTH_SIZE; totalSize -= LENGTH_SIZE; if (!first.isReadable()) { buffers.removeFirst().release(); } return nextFrameSize; } while (frameLenBuf.readableBytes() < LENGTH_SIZE) { ByteBuf next = buffers.getFirst(); int toRead = Math.min(next.readableBytes(), LENGTH_SIZE - frameLenBuf.readableBytes()); frameLenBuf.writeBytes(next, toRead); if (!next.isReadable()) { buffers.removeFirst().release(); } } nextFrameSize = frameLenBuf.readLong() - LENGTH_SIZE; totalSize -= LENGTH_SIZE; frameLenBuf.clear(); return nextFrameSize; } private ByteBuf decodeNext() { long frameSize = decodeFrameSize(); if (frameSize == UNKNOWN_FRAME_SIZE) { return null; } if (frameBuf == null) { JavaUtils.checkArgument(frameSize < MAX_FRAME_SIZE, \"Too large frame: %s\", frameSize); JavaUtils.checkArgument(frameSize > 0, \"Frame length should be positive: %s\", frameSize); frameRemainingBytes = (int) frameSize; // If buffers is empty, then return immediately for more input data. if (buffers.isEmpty()) { return null; } // Otherwise, if the first buffer holds the entire frame, we attempt to // build frame with it and return. if (buffers.getFirst().readableBytes() >= frameRemainingBytes) { // Reset buf and size for next frame. frameBuf = null; nextFrameSize = UNKNOWN_FRAME_SIZE; return nextBufferForFrame(frameRemainingBytes); } // Other cases, create a composite buffer to manage all the buffers. frameBuf = buffers.getFirst().alloc().compositeBuffer(Integer.MAX_VALUE); } while (frameRemainingBytes > 0 && !buffers.isEmpty()) { ByteBuf next = nextBufferForFrame(frameRemainingBytes); frameRemainingBytes -= next.readableBytes(); frameBuf.addComponent(true, next); } // If the delta size of frameBuf exceeds the threshold, then we do consolidation // to reduce memory consumption. if (frameBuf.capacity() - consolidatedFrameBufSize > consolidateThreshold) { int newNumComponents = frameBuf.numComponents() - consolidatedNumComponents; frameBuf.consolidate(consolidatedNumComponents, newNumComponents); consolidatedFrameBufSize = frameBuf.capacity(); consolidatedNumComponents = frameBuf.numComponents(); } if (frameRemainingBytes > 0) { return null; } return consumeCurrentFrameBuf(); } private ByteBuf consumeCurrentFrameBuf() { ByteBuf frame = frameBuf; // Reset buf and size for next frame. frameBuf = null; consolidatedFrameBufSize = 0; consolidatedNumComponents = 0; nextFrameSize = UNKNOWN_FRAME_SIZE; return frame; } /** * Takes the first buffer in the internal list, and either adjust it to fit in the frame * (by taking a slice out of it) or remove it from the internal list. */ private ByteBuf nextBufferForFrame(int bytesToRead) { ByteBuf buf = buffers.getFirst(); ByteBuf frame; if (buf.readableBytes() > bytesToRead) { frame = buf.retain().readSlice(bytesToRead); totalSize -= bytesToRead; } else { frame = buf; buffers.removeFirst(); totalSize -= frame.readableBytes(); } return frame; } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (interceptor != null) { interceptor.channelInactive(); } super.channelInactive(ctx); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { if (interceptor != null) { interceptor.exceptionCaught(cause); } super.exceptionCaught(ctx, cause); } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { // Release all buffers that are still in our ownership. // Doing this in handlerRemoved(...) guarantees that this will happen in all cases: // - When the Channel becomes inactive // - When the decoder is removed from the ChannelPipeline for (ByteBuf b : buffers) { b.release(); } buffers.clear(); frameLenBuf.release(); ByteBuf frame = consumeCurrentFrameBuf(); if (frame != null) { frame.release(); } super.handlerRemoved(ctx); } public void setInterceptor(Interceptor interceptor) { JavaUtils.checkState(this.interceptor == null, \"Already have an interceptor.\"); this.interceptor = interceptor; } /** * @return Whether the interceptor is still active after processing the data. */ private boolean feedInterceptor(ByteBuf buf) throws Exception { if (interceptor != null && !interceptor.handle(buf)) { interceptor = null; } return interceptor != null; } public interface Interceptor { /** * Handles data received from the remote end. * * @param data Buffer containing data. * @return \"true\" if the interceptor expects more data, \"false\" to uninstall the interceptor. */ boolean handle(ByteBuf data) throws Exception; /** Called if an exception is thrown in the channel pipeline. */ void exceptionCaught(Throwable cause) throws Exception; /** Called if the channel is closed and the interceptor is still installed. */ void channelInactive() throws Exception; } }",
        "public class TransportFrameDecoderSuite { private static final Logger logger = LoggerFactory.getLogger(TransportFrameDecoderSuite.class); private static Random RND = new Random(); @AfterAll public static void cleanup() { RND = null; } @Test public void testFrameDecoding() throws Exception { TransportFrameDecoder decoder = new TransportFrameDecoder(); ChannelHandlerContext ctx = mockChannelHandlerContext(); ByteBuf data = createAndFeedFrames(100, decoder, ctx); verifyAndCloseDecoder(decoder, ctx, data); } @Test public void testConsolidationPerf() throws Exception { long[] testingConsolidateThresholds = new long[] { ByteUnit.MiB.toBytes(1), ByteUnit.MiB.toBytes(5), ByteUnit.MiB.toBytes(10), ByteUnit.MiB.toBytes(20), ByteUnit.MiB.toBytes(30), ByteUnit.MiB.toBytes(50), ByteUnit.MiB.toBytes(80), ByteUnit.MiB.toBytes(100), ByteUnit.MiB.toBytes(300), ByteUnit.MiB.toBytes(500), Long.MAX_VALUE }; for (long threshold : testingConsolidateThresholds) { TransportFrameDecoder decoder = new TransportFrameDecoder(threshold); ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); List<ByteBuf> retained = new ArrayList<>(); when(ctx.fireChannelRead(any())).thenAnswer(in -> { ByteBuf buf = (ByteBuf) in.getArguments()[0]; retained.add(buf); return null; }); // Testing multiple messages int numMessages = 3; long targetBytes = ByteUnit.MiB.toBytes(300); int pieceBytes = (int) ByteUnit.KiB.toBytes(32); for (int i = 0; i < numMessages; i++) { try { long writtenBytes = 0; long totalTime = 0; ByteBuf buf = Unpooled.buffer(8); buf.writeLong(8 + targetBytes); decoder.channelRead(ctx, buf); while (writtenBytes < targetBytes) { buf = Unpooled.buffer(pieceBytes * 2); ByteBuf writtenBuf = Unpooled.buffer(pieceBytes).writerIndex(pieceBytes); buf.writeBytes(writtenBuf); writtenBuf.release(); long start = System.currentTimeMillis(); decoder.channelRead(ctx, buf); long elapsedTime = System.currentTimeMillis() - start; totalTime += elapsedTime; writtenBytes += pieceBytes; } logger.info(\"Writing 300MiB frame buf with consolidation of threshold \" + threshold + \" took \" + totalTime + \" millis\"); } finally { for (ByteBuf buf : retained) { release(buf); } } } long totalBytesGot = 0; for (ByteBuf buf : retained) { totalBytesGot += buf.capacity(); } assertEquals(numMessages, retained.size()); assertEquals(targetBytes * numMessages, totalBytesGot); } } @Test public void testInterception() throws Exception { int interceptedReads = 3; TransportFrameDecoder decoder = new TransportFrameDecoder(); TransportFrameDecoder.Interceptor interceptor = spy(new MockInterceptor(interceptedReads)); ChannelHandlerContext ctx = mockChannelHandlerContext(); byte[] data = new byte[8]; ByteBuf len = Unpooled.copyLong(8 + data.length); ByteBuf dataBuf = Unpooled.wrappedBuffer(data); try { decoder.setInterceptor(interceptor); for (int i = 0; i < interceptedReads; i++) { decoder.channelRead(ctx, dataBuf); assertEquals(0, dataBuf.refCnt()); dataBuf = Unpooled.wrappedBuffer(data); } decoder.channelRead(ctx, len); decoder.channelRead(ctx, dataBuf); verify(interceptor, times(interceptedReads)).handle(any(ByteBuf.class)); verify(ctx).fireChannelRead(any(ByteBuf.class)); assertEquals(0, len.refCnt()); assertEquals(0, dataBuf.refCnt()); } finally { release(len); release(dataBuf); } } @Test public void testRetainedFrames() throws Exception { TransportFrameDecoder decoder = new TransportFrameDecoder(); AtomicInteger count = new AtomicInteger(); List<ByteBuf> retained = new ArrayList<>(); ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); when(ctx.fireChannelRead(any())).thenAnswer(in -> { // Retain a few frames but not others. ByteBuf buf = (ByteBuf) in.getArguments()[0]; if (count.incrementAndGet() % 2 == 0) { retained.add(buf); } else { buf.release(); } return null; }); ByteBuf data = createAndFeedFrames(100, decoder, ctx); try { // Verify all retained buffers are readable. for (ByteBuf b : retained) { byte[] tmp = new byte[b.readableBytes()]; b.readBytes(tmp); b.release(); } verifyAndCloseDecoder(decoder, ctx, data); } finally { for (ByteBuf b : retained) { release(b); } } } @Test public void testSplitLengthField() throws Exception { byte[] frame = new byte[1024 * (RND.nextInt(31) + 1)]; ByteBuf buf = Unpooled.buffer(frame.length + 8); buf.writeLong(frame.length + 8); buf.writeBytes(frame); TransportFrameDecoder decoder = new TransportFrameDecoder(); ChannelHandlerContext ctx = mockChannelHandlerContext(); try { decoder.channelRead(ctx, buf.readSlice(RND.nextInt(7)).retain()); verify(ctx, never()).fireChannelRead(any(ByteBuf.class)); decoder.channelRead(ctx, buf); verify(ctx).fireChannelRead(any(ByteBuf.class)); assertEquals(0, buf.refCnt()); } finally { decoder.channelInactive(ctx); release(buf); } } @Test public void testNegativeFrameSize() { assertThrows(IllegalArgumentException.class, () -> testInvalidFrame(-1)); } @Test public void testEmptyFrame() { // 8 because frame size includes the frame length. assertThrows(IllegalArgumentException.class, () -> testInvalidFrame(8)); } /** * Creates a number of randomly sized frames and feed them to the given decoder, verifying * that the frames were read. */ private ByteBuf createAndFeedFrames( int frameCount, TransportFrameDecoder decoder, ChannelHandlerContext ctx) throws Exception { ByteBuf data = Unpooled.buffer(); for (int i = 0; i < frameCount; i++) { byte[] frame = new byte[1024 * (RND.nextInt(31) + 1)]; data.writeLong(frame.length + 8); data.writeBytes(frame); } try { while (data.isReadable()) { int size = RND.nextInt(4 * 1024) + 256; decoder.channelRead(ctx, data.readSlice(Math.min(data.readableBytes(), size)).retain()); } verify(ctx, times(frameCount)).fireChannelRead(any(ByteBuf.class)); } catch (Exception e) { release(data); throw e; } return data; } private void verifyAndCloseDecoder( TransportFrameDecoder decoder, ChannelHandlerContext ctx, ByteBuf data) throws Exception { try { decoder.channelInactive(ctx); assertTrue(data.release(), \"There shouldn't be dangling references to the data.\"); } finally { release(data); } } private void testInvalidFrame(long size) throws Exception { TransportFrameDecoder decoder = new TransportFrameDecoder(); ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); ByteBuf frame = Unpooled.copyLong(size); try { decoder.channelRead(ctx, frame); } finally { release(frame); } } private ChannelHandlerContext mockChannelHandlerContext() { ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); when(ctx.fireChannelRead(any())).thenAnswer(in -> { ByteBuf buf = (ByteBuf) in.getArguments()[0]; buf.release(); return null; }); return ctx; } private void release(ByteBuf buf) { if (buf.refCnt() > 0) { buf.release(buf.refCnt()); } } private static class MockInterceptor implements TransportFrameDecoder.Interceptor { private int remainingReads; MockInterceptor(int readCount) { this.remainingReads = readCount; } @Override public boolean handle(ByteBuf data) throws Exception { data.readerIndex(data.readerIndex() + data.readableBytes()); assertFalse(data.isReadable()); remainingReads -= 1; return remainingReads != 0; } @Override public void exceptionCaught(Throwable cause) throws Exception { } @Override public void channelInactive() throws Exception { } } }"
      ],
      "key_facts": [
        "Custom Netty frame decoder for Apache Spark",
        "Uses 8-byte length prefix protocol",
        "Supports interceptor mode",
        "Consolidates buffers above 20MB threshold to reduce fragmentation",
        "Most important fields include: LENGTH_SIZE = 8 - size of incoming frames, MAX_FRAME_SIZE = Integer.MAX_VALUE - maximum size of frame, CONSOLIDATE_THRESHOLD = 20 MB - buffer consolidation threshold, buffers - list of incoming ByteBuf buffers, frameLenBuf - 8-byte buffer to read length of frame, frameBuf - Composite buffer that allows to piece frame from many buffers, totalSize - size of data in buffer, nextFrameSize - size of next frame to decode, interceptor - allows to read raw data before it's framed."
      ],
      "key_entities": [
        "TransportFrameDecoder",
        "TransportFrameDecoderSuite"
      ],
      "junie_stats": {
        "with_mcp": {
          "answer": "### Overview\n`TransportFrameDecoder` is a concrete class that extends `ChannelInboundHandlerAdapter`. Its role, as visible in the code, is to consume inbound Netty `ByteBuf` data, accumulate it, optionally pass it through an `Interceptor`, decode frames (using an internal length-processing flow), and forward fully decoded frames upstream via `ctx.fireChannelRead`.\n\n### Constants and configuration\n- `public static final String HANDLER_NAME = \"frameDecoder\"`\n- `private static final int LENGTH_SIZE = 8`\n- `private static final int MAX_FRAME_SIZE = Integer.MAX_VALUE`\n- `private static final int UNKNOWN_FRAME_SIZE = -1`\n- `private static final long CONSOLIDATE_THRESHOLD = 20 * 1024 * 1024`\n\n### Fields\n- `private final LinkedList<ByteBuf> buffers = new LinkedList<>();`\n  - Holds inbound `ByteBuf` chunks awaiting decoding.\n- `private final ByteBuf frameLenBuf = Unpooled.buffer(LENGTH_SIZE, LENGTH_SIZE);`\n  - A fixed-size buffer (capacity 8 bytes) used when decoding a frame length.\n- `private final long consolidateThreshold;`\n  - Threshold value controlling when to consolidate buffers (exact logic not shown here, but the value is provided via constructor).\n- `private CompositeByteBuf frameBuf = null;`\n  - Buffer used to assemble a frame payload (composite to avoid copies).\n- `private long consolidatedFrameBufSize = 0;`\n- `private int consolidatedNumComponents = 0;`\n- `private long totalSize = 0;`\n  - Tracks the total number of readable bytes currently held across `buffers`.\n- `private long nextFrameSize = UNKNOWN_FRAME_SIZE;`\n  - Tracks the expected size of the next frame (unknown until the frame size is decoded).\n- `private int frameRemainingBytes = UNKNOWN_FRAME_SIZE;`\n  - Tracks how many bytes remain to complete the current frame payload.\n- `private volatile Interceptor interceptor;`\n  - Optional `Interceptor` that, if set, consumes data before regular frame decoding proceeds.\n\n### Constructors\n- `public TransportFrameDecoder()`\n  - Delegates to the other constructor with `CONSOLIDATE_THRESHOLD`.\n- `@VisibleForTesting TransportFrameDecoder(long consolidateThreshold)`\n  - Initializes the instance with a specific `consolidateThreshold` value.\n\n### Methods (visible portions)\n- `@Override public void channelRead(ChannelHandlerContext ctx, Object data) throws Exception`\n  - Casts `data` to `ByteBuf`, enqueues it into `buffers`, and increases `totalSize` by `in.readableBytes()`.\n  - Loops while there is buffered data:\n    - If `interceptor != null`:\n      - Obtains the first buffer and calls `feedInterceptor(first)`.\n      - After feeding, computes how many bytes were consumed (`read`) by comparing readable bytes before/after.\n      - If the first buffer was fully consumed, removes and releases it.\n      - Decreases `totalSize` by the number of bytes read.\n      - Continues looping, giving the interceptor another chance if it remains active.\n    - Else (no active interceptor):\n      - Calls `decodeNext()` to try to produce a complete frame `ByteBuf`.\n      - If `decodeNext()` returns `null`, breaks out of the loop (no full frame yet).\n      - If a frame is returned, forwards it upstream with `ctx.fireChannelRead(frame)` and loops to try decoding more.\n\n- `private long decodeFrameSize()`\n  - Returns `nextFrameSize` immediately if it is already known or if `totalSize < LENGTH_SIZE`.\n  - Otherwise (enough data is available), proceeds to read the frame size from the buffered data. The visible comment indicates it tries to read from the first buffer if it contains all needed bytes; otherwise, it performs additional steps (not shown in the excerpt) to extract the size.\n\n- Referenced but not shown in the snippet:\n  - `private boolean feedInterceptor(ByteBuf first)` (inferred from usage `if (feedInterceptor(first)) { ... }`).\n  - `private ByteBuf decodeNext()` (inferred from `ByteBuf frame = decodeNext();`).\n\n### Behavior summary\n- Accumulates inbound `ByteBuf` instances in `buffers` and tracks their total readable bytes in `totalSize`.\n- If an `Interceptor` is present, it is given first chance to consume data; data consumed by the interceptor is accounted for and fully consumed buffers are released.\n- Once no interceptor is active, the decoder attempts to produce frames using a length-driven process:\n  - It decodes an upcoming frame size using `LENGTH_SIZE` (8 bytes) via `frameLenBuf`.\n  - It then assembles the frame payload (with support for composite buffers), tracking `frameRemainingBytes` and related consolidation counters.\n- When a complete frame is available, it is passed upstream via `ctx.fireChannelRead(frame)`.\n\n### Notable limits and thresholds\n- `MAX_FRAME_SIZE` is defined as `Integer.MAX_VALUE`.\n- Buffer consolidation is governed by `consolidateThreshold` (default `20 * 1024 * 1024`), though the exact consolidation logic is not shown in the provided snippet.\n\n### Relationships\n- Inherits from `ChannelInboundHandlerAdapter`.\n- Works with Netty buffer types: `ByteBuf`, `CompositeByteBuf`, and `Unpooled`.\n- Uses an inner/associated `Interceptor` type (exact definition not shown here).\n\n### Suggested next step\nIf you want a complete, line-by-line description including the bodies of `decodeNext`, `feedInterceptor`, and the full `decodeFrameSize` logic, I can fetch and summarize those methods as well. Would you like me to extract those parts next?",
          "time": 0,
          "tokens": 0,
          "hallucination": 1,
          "correctness": 4,
          "used_context": [
            "org.apache.spark.network.util.TransportFrameDecoder\npublic class TransportFrameDecoder extends ChannelInboundHandlerAdapter { public static final String HANDLER_NAME = \"frameDecoder\"; private static final int LENGTH_SIZE = 8; private static final int MAX_FRAME_SIZE = Integer.MAX_VALUE; private static final int UNKNOWN_FRAME_SIZE = -1; private static final long CONSOLIDATE_THRESHOLD = 20 * 1024 * 1024; private final LinkedList<ByteBuf> buffers = new LinkedList<>(); private final ByteBuf frameLenBuf = Unpooled.buffer(LENGTH_SIZE, LENGTH_SIZE); private final long consolidateThreshold; private CompositeByteBuf frameBuf = null; private long consolidatedFrameBufSize = 0; private int consolidatedNumComponents = 0; private long totalSize = 0; private long nextFrameSize = UNKNOWN_FRAME_SIZE; private int frameRemainingBytes = UNKNOWN_FRAME_SIZE; private volatile Interceptor interceptor; public TransportFrameDecoder() { this(CONSOLIDATE_THRESHOLD); } @VisibleForTesting TransportFrameDecoder(long consolidateThreshold) { this.consolidateThreshold = consolidateThreshold; } @Override public void channelRead(ChannelHandlerContext ctx, Object data) throws Exception { ByteBuf in = (ByteBuf) data; buffers.add(in); totalSize += in.readableBytes(); while (!buffers.isEmpty()) { // First, feed the interceptor, and if it's still, active, try again. if (interceptor != null) { ByteBuf first = buffers.getFirst(); int available = first.readableBytes(); if (feedInterceptor(first)) { assert !first.isReadable() : \"Interceptor still active but buffer has data.\"; } int read = available - first.readableBytes(); if (read == available) { buffers.removeFirst().release(); } totalSize -= read; } else { // Interceptor is not active, so try to decode one frame. ByteBuf frame = decodeNext(); if (frame == null) { break; } ctx.fireChannelRead(frame); } } } private long decodeFrameSize() { if (nextFrameSize != UNKNOWN_FRAME_SIZE || totalSize < LENGTH_SIZE) { return nextFrameSize; } // We know there's enough data. If the first buffer contains all the data, great. Otherwise, // hold the bytes for the frame length in a composite buffer until we have enough data to read // the frame size. Normally, it should be rare to need more than one buffer to read the frame // size. ByteBuf first = buffers.getFirst(); if (first.readableBytes() >= LENGTH_SIZE) { nextFrameSize = first.readLong() - LENGTH_SIZE; totalSize -= LENGTH_SIZE; if (!first.isReadable()) { buffers.removeFirst().release(); } return nextFrameSize; } while (frameLenBuf.readableBytes() < LENGTH_SIZE) { ByteBuf next = buffers.getFirst(); int toRead = Math.min(next.readableBytes(), LENGTH_SIZE - frameLenBuf.readableBytes()); frameLenBuf.writeBytes(next, toRead); if (!next.isReadable()) { buffers.removeFirst().release(); } } nextFrameSize = frameLenBuf.readLong() - LENGTH_SIZE; totalSize -= LENGTH_SIZE; frameLenBuf.clear(); return nextFrameSize; } private ByteBuf decodeNext() { long frameSize = decodeFrameSize(); if (frameSize == UNKNOWN_FRAME_SIZE) { return null; } if (frameBuf == null) { JavaUtils.checkArgument(frameSize < MAX_FRAME_SIZE, \"Too large frame: %s\", frameSize); JavaUtils.checkArgument(frameSize > 0, \"Frame length should be positive: %s\", frameSize); frameRemainingBytes = (int) frameSize; // If buffers is empty, then return immediately for more input data. if (buffers.isEmpty()) { return null; } // Otherwise, if the first buffer holds the entire frame, we attempt to // build frame with it and return. if (buffers.getFirst().readableBytes() >= frameRemainingBytes) { // Reset buf and size for next frame. frameBuf = null; nextFrameSize = UNKNOWN_FRAME_SIZE; return nextBufferForFrame(frameRemainingBytes); } // Other cases, create a composite buffer to manage all the buffers. frameBuf = buffers.getFirst().alloc().compositeBuffer(Integer.MAX_VALUE); } while (frameRemainingBytes > 0 && !buffers.isEmpty()) { ByteBuf next = nextBufferForFrame(frameRemainingBytes); frameRemainingBytes -= next.readableBytes(); frameBuf.addComponent(true, next); } // If the delta size of frameBuf exceeds the threshold, then we do consolidation // to reduce memory consumption. if (frameBuf.capacity() - consolidatedFrameBufSize > consolidateThreshold) { int newNumComponents = frameBuf.numComponents() - consolidatedNumComponents; frameBuf.consolidate(consolidatedNumComponents, newNumComponents); consolidatedFrameBufSize = frameBuf.capacity(); consolidatedNumComponents = frameBuf.numComponents(); } if (frameRemainingBytes > 0) { return null; } return consumeCurrentFrameBuf(); } private ByteBuf consumeCurrentFrameBuf() { ByteBuf frame = frameBuf; // Reset buf and size for next frame. frameBuf = null; consolidatedFrameBufSize = 0; consolidatedNumComponents = 0; nextFrameSize = UNKNOWN_FRAME_SIZE; return frame; } /** * Takes the first buffer in the internal list, and either adjust it to fit in the frame * (by taking a slice out of it) or remove it from the internal list. */ private ByteBuf nextBufferForFrame(int bytesToRead) { ByteBuf buf = buffers.getFirst(); ByteBuf frame; if (buf.readableBytes() > bytesToRead) { frame = buf.retain().readSlice(bytesToRead); totalSize -= bytesToRead; } else { frame = buf; buffers.removeFirst(); totalSize -= frame.readableBytes(); } return frame; } @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception { if (interceptor != null) { interceptor.channelInactive(); } super.channelInactive(ctx); } @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { if (interceptor != null) { interceptor.exceptionCaught(cause); } super.exceptionCaught(ctx, cause); } @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception { // Release all buffers that are still in our ownership. // Doing this in handlerRemoved(...) guarantees that this will happen in all cases: // - When the Channel becomes inactive // - When the decoder is removed from the ChannelPipeline for (ByteBuf b : buffers) { b.release(); } buffers.clear(); frameLenBuf.release(); ByteBuf frame = consumeCurrentFrameBuf(); if (frame != null) { frame.release(); } super.handlerRemoved(ctx); } public void setInterceptor(Interceptor interceptor) { JavaUtils.checkState(this.interceptor == null, \"Already have an interceptor.\"); this.interceptor = interceptor; } /** * @return Whether the interceptor is still active after processing the data. */ private boolean feedInterceptor(ByteBuf buf) throws Exception { if (interceptor != null && !interceptor.handle(buf)) { interceptor = null; } return interceptor != null; } public interface Interceptor { /** * Handles data received from the remote end. * * @param data Buffer containing data. * @return \"true\" if the interceptor expects more data, \"false\" to uninstall the interceptor. */ boolean handle(ByteBuf data) throws Exception; /** Called if an exception is thrown in the channel pipeline. */ void exceptionCaught(Throwable cause) throws Exception; /** Called if the channel is closed and the interceptor is still installed. */ void channelInactive() throws Exception; } }",
            "org.apache.spark.network.util.TransportFrameDecoderSuite\npublic class TransportFrameDecoderSuite { private static final Logger logger = LoggerFactory.getLogger(TransportFrameDecoderSuite.class); private static Random RND = new Random(); @AfterAll public static void cleanup() { RND = null; } @Test public void testFrameDecoding() throws Exception { TransportFrameDecoder decoder = new TransportFrameDecoder(); ChannelHandlerContext ctx = mockChannelHandlerContext(); ByteBuf data = createAndFeedFrames(100, decoder, ctx); verifyAndCloseDecoder(decoder, ctx, data); } @Test public void testConsolidationPerf() throws Exception { long[] testingConsolidateThresholds = new long[] { ByteUnit.MiB.toBytes(1), ByteUnit.MiB.toBytes(5), ByteUnit.MiB.toBytes(10), ByteUnit.MiB.toBytes(20), ByteUnit.MiB.toBytes(30), ByteUnit.MiB.toBytes(50), ByteUnit.MiB.toBytes(80), ByteUnit.MiB.toBytes(100), ByteUnit.MiB.toBytes(300), ByteUnit.MiB.toBytes(500), Long.MAX_VALUE }; for (long threshold : testingConsolidateThresholds) { TransportFrameDecoder decoder = new TransportFrameDecoder(threshold); ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); List<ByteBuf> retained = new ArrayList<>(); when(ctx.fireChannelRead(any())).thenAnswer(in -> { ByteBuf buf = (ByteBuf) in.getArguments()[0]; retained.add(buf); return null; }); // Testing multiple messages int numMessages = 3; long targetBytes = ByteUnit.MiB.toBytes(300); int pieceBytes = (int) ByteUnit.KiB.toBytes(32); for (int i = 0; i < numMessages; i++) { try { long writtenBytes = 0; long totalTime = 0; ByteBuf buf = Unpooled.buffer(8); buf.writeLong(8 + targetBytes); decoder.channelRead(ctx, buf); while (writtenBytes < targetBytes) { buf = Unpooled.buffer(pieceBytes * 2); ByteBuf writtenBuf = Unpooled.buffer(pieceBytes).writerIndex(pieceBytes); buf.writeBytes(writtenBuf); writtenBuf.release(); long start = System.currentTimeMillis(); decoder.channelRead(ctx, buf); long elapsedTime = System.currentTimeMillis() - start; totalTime += elapsedTime; writtenBytes += pieceBytes; } logger.info(\"Writing 300MiB frame buf with consolidation of threshold \" + threshold + \" took \" + totalTime + \" millis\"); } finally { for (ByteBuf buf : retained) { release(buf); } } } long totalBytesGot = 0; for (ByteBuf buf : retained) { totalBytesGot += buf.capacity(); } assertEquals(numMessages, retained.size()); assertEquals(targetBytes * numMessages, totalBytesGot); } } @Test public void testInterception() throws Exception { int interceptedReads = 3; TransportFrameDecoder decoder = new TransportFrameDecoder(); TransportFrameDecoder.Interceptor interceptor = spy(new MockInterceptor(interceptedReads)); ChannelHandlerContext ctx = mockChannelHandlerContext(); byte[] data = new byte[8]; ByteBuf len = Unpooled.copyLong(8 + data.length); ByteBuf dataBuf = Unpooled.wrappedBuffer(data); try { decoder.setInterceptor(interceptor); for (int i = 0; i < interceptedReads; i++) { decoder.channelRead(ctx, dataBuf); assertEquals(0, dataBuf.refCnt()); dataBuf = Unpooled.wrappedBuffer(data); } decoder.channelRead(ctx, len); decoder.channelRead(ctx, dataBuf); verify(interceptor, times(interceptedReads)).handle(any(ByteBuf.class)); verify(ctx).fireChannelRead(any(ByteBuf.class)); assertEquals(0, len.refCnt()); assertEquals(0, dataBuf.refCnt()); } finally { release(len); release(dataBuf); } } @Test public void testRetainedFrames() throws Exception { TransportFrameDecoder decoder = new TransportFrameDecoder(); AtomicInteger count = new AtomicInteger(); List<ByteBuf> retained = new ArrayList<>(); ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); when(ctx.fireChannelRead(any())).thenAnswer(in -> { // Retain a few frames but not others. ByteBuf buf = (ByteBuf) in.getArguments()[0]; if (count.incrementAndGet() % 2 == 0) { retained.add(buf); } else { buf.release(); } return null; }); ByteBuf data = createAndFeedFrames(100, decoder, ctx); try { // Verify all retained buffers are readable. for (ByteBuf b : retained) { byte[] tmp = new byte[b.readableBytes()]; b.readBytes(tmp); b.release(); } verifyAndCloseDecoder(decoder, ctx, data); } finally { for (ByteBuf b : retained) { release(b); } } } @Test public void testSplitLengthField() throws Exception { byte[] frame = new byte[1024 * (RND.nextInt(31) + 1)]; ByteBuf buf = Unpooled.buffer(frame.length + 8); buf.writeLong(frame.length + 8); buf.writeBytes(frame); TransportFrameDecoder decoder = new TransportFrameDecoder(); ChannelHandlerContext ctx = mockChannelHandlerContext(); try { decoder.channelRead(ctx, buf.readSlice(RND.nextInt(7)).retain()); verify(ctx, never()).fireChannelRead(any(ByteBuf.class)); decoder.channelRead(ctx, buf); verify(ctx).fireChannelRead(any(ByteBuf.class)); assertEquals(0, buf.refCnt()); } finally { decoder.channelInactive(ctx); release(buf); } } @Test public void testNegativeFrameSize() { assertThrows(IllegalArgumentException.class, () -> testInvalidFrame(-1)); } @Test public void testEmptyFrame() { // 8 because frame size includes the frame length. assertThrows(IllegalArgumentException.class, () -> testInvalidFrame(8)); } /** * Creates a number of randomly sized frames and feed them to the given decoder, verifying * that the frames were read. */ private ByteBuf createAndFeedFrames( int frameCount, TransportFrameDecoder decoder, ChannelHandlerContext ctx) throws Exception { ByteBuf data = Unpooled.buffer(); for (int i = 0; i < frameCount; i++) { byte[] frame = new byte[1024 * (RND.nextInt(31) + 1)]; data.writeLong(frame.length + 8); data.writeBytes(frame); } try { while (data.isReadable()) { int size = RND.nextInt(4 * 1024) + 256; decoder.channelRead(ctx, data.readSlice(Math.min(data.readableBytes(), size)).retain()); } verify(ctx, times(frameCount)).fireChannelRead(any(ByteBuf.class)); } catch (Exception e) { release(data); throw e; } return data; } private void verifyAndCloseDecoder( TransportFrameDecoder decoder, ChannelHandlerContext ctx, ByteBuf data) throws Exception { try { decoder.channelInactive(ctx); assertTrue(data.release(), \"There shouldn't be dangling references to the data.\"); } finally { release(data); } } private void testInvalidFrame(long size) throws Exception { TransportFrameDecoder decoder = new TransportFrameDecoder(); ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); ByteBuf frame = Unpooled.copyLong(size); try { decoder.channelRead(ctx, frame); } finally { release(frame); } } private ChannelHandlerContext mockChannelHandlerContext() { ChannelHandlerContext ctx = mock(ChannelHandlerContext.class); when(ctx.fireChannelRead(any())).thenAnswer(in -> { ByteBuf buf = (ByteBuf) in.getArguments()[0]; buf.release(); return null; }); return ctx; } private void release(ByteBuf buf) { if (buf.refCnt() > 0) { buf.release(buf.refCnt()); } } private static class MockInterceptor implements TransportFrameDecoder.Interceptor { private int remainingReads; MockInterceptor(int readCount) { this.remainingReads = readCount; } @Override public boolean handle(ByteBuf data) throws Exception { data.readerIndex(data.readerIndex() + data.readableBytes()); assertFalse(data.isReadable()); remainingReads -= 1; return remainingReads != 0; } @Override public void exceptionCaught(Throwable cause) throws Exception { } @Override public void channelInactive() throws Exception { } } }"
          ]
        },
        "without_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0
        }
      }
    },
    {
      "id": "Q002",
      "question": "Describe UTF8String class",
      "category": "definition",
      "ground_truth_contexts": [
      ],
      "key_facts": [
      ],
      "key_entities": [
      ],
      "junie_stats": {
        "with_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0,
          "used_context": ""
        },
        "without_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0
        }
      }
    },
    {
      "id": "Q006",
      "question": "What are 5 classes with most lines of code?",
      "category": "top",
      "ground_truth_contexts": [
        "CollationSupportSuite - 3861, UTF8String - 2190, RemoteBlockPushResolver - 2165, JavaDatasetSuite - 2127, ParquetVectorUpdaterFactory - 1724"
      ],
      "key_facts": [
        "CollationSupportSuite - 3861",
        "UTF8String - 2190",
        "RemoteBlockPushResolver - 2165",
        "JavaDatasetSuite - 2127",
        "ParquetVectorUpdaterFactory - 1724"
      ],
      "key_entities": [
        "CollationSupportSuite",
        "UTF8String",
        "RemoteBlockPushResolver",
        "JavaDatasetSuite",
        "ParquetVectorUpdaterFactory"
      ],
      "junie_stats": {
        "with_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0,
          "used_context": [
          ]
        },
        "without_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0
        }
      }
    },
    {
      "id": "Q007",
      "question": "Describe 5 most important classes in project.",
      "category": "top",
      "ground_truth_contexts": [
      ],
      "key_facts": [
      ],
      "key_entities": [
        "CollationSupportSuite",
        "UTF8String",
        "RemoteBlockPushResolver",
        "JavaDatasetSuite",
        "ParquetVectorUpdaterFactory"
      ],
      "junie_stats": {
        "with_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0,
          "used_context": [
          ]
        },
        "without_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0
        }
      }
    },
    {
      "id": "Q008",
      "question": "What are 5 least important classes in project and value of combined metric for them?",
      "category": "top",
      "ground_truth_contexts": [
        "Class1 - 14537.00 Offset - 25735.00 PrivateClassTest - 36505.00 UnsupportedStoreVersionException - 37421.00 Class2 - 39818.00"
      ],
      "key_facts": [
        "Class1 - 14537.00",
        "Offset - 25735.00",
        "PrivateClassTest - 36505.00",
        "UnsupportedStoreVersionException - 37421.00",
        "Class2 - 39818.00"
      ],
      "key_entities": [
        "Class1",
        "Offset",
        "PrivateClassTest",
        "UnsupportedStoreVersionException",
        "Class2"
      ],
      "junie_stats": {
        "with_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0,
          "used_context": [
          ]
        },
        "without_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0
        }
      }
    },
    {
      "id": "Q009",
      "question": "What are all entities with 0 neighbors?",
      "category": "top",
      "ground_truth_contexts": [
        "Class1 - 14537.00 Offset - 25735.00 PrivateClassTest - 36505.00 UnsupportedStoreVersionException - 37421.00 Class2 - 39818.00"
      ],
      "key_facts": [
        "Class1 - 14537.00",
        "Offset - 25735.00",
        "PrivateClassTest - 36505.00",
        "UnsupportedStoreVersionException - 37421.00",
        "Class2 - 39818.00"
      ],
      "key_entities": [
        "Class1",
        "Offset",
        "PrivateClassTest",
        "UnsupportedStoreVersionException",
        "Class2"
      ],
      "junie_stats": {
        "with_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0,
          "used_context": [
          ]
        },
        "without_mcp": {
          "answer": "",
          "time": 0,
          "tokens": 0,
          "hallucination": 0,
          "correctness": 0
        }
      }
    }
  ]
}